PART-2

ğŸ¤– 1ï¸âƒ£ What is Machine Learning?

ML = Making machines learn patterns from data without being explicitly programmed.

Types of ML:

Supervised Learning â†’ Learn from labeled data.

Regression (predict numbers: house price, stock price).

Classification (predict categories: spam/not spam).

Unsupervised Learning â†’ No labels, just structure.

Clustering (grouping: customer segmentation).

Dimensionality Reduction (PCA, t-SNE).

Reinforcement Learning â†’ Agent learns by trial & error (self-driving car, game AI).

ğŸ“ˆ 2ï¸âƒ£ Key Algorithms
(a) Regression

Linear Regression â€“ predicts continuous values.

Equation:

y = w1x1 + w2x2 + ..... + b

ğŸ“Œ Example: Predict salary from years of experience.

(b) Classification

Logistic Regression â€“ predicts probabilities (yes/no).

Uses sigmoid function to squash output between 0â€“1.

ğŸ“Œ Example: Spam vs. Not Spam.

(c) Decision Trees & Random Forest

Tree splits data based on features.

Random Forest = multiple trees + majority vote (reduces overfitting).


(d) Clustering

K-Means Clustering â€“ groups data into K clusters.
Steps:

Choose K cluster centers.

Assign points to nearest center.

Recompute centers.

Repeat.

ğŸ“Œ Example: Grouping customers by spending habits.

3ï¸âƒ£ Training & Evaluation
Common Metrics:

Regression â†’ MSE, RMSE, MAE, RÂ².

Classification â†’ Accuracy, Precision, Recall, F1-score, ROC-AUC.

ğŸ‘‰ Important Example:
Dataset = 95% negative class, 5% positive.
If model predicts all â€œnegativeâ€ â†’ Accuracy = 95%, but useless!
ğŸ‘‰ Use Precision, Recall, F1.

Overfitting vs Underfitting

Overfitting â†’ Model learns noise (great on train, bad on test).

Underfitting â†’ Model too simple (bad on both).

âœ… Solutions:

Overfitting â†’ Regularization (L1/L2), Dropoutl.

4ï¸âƒ£ Mini Example (Python), Pruning trees.

Underfitting â†’ Add features, complex mode
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# Fake data: Years of experience vs Salary
X = [[1],[2],[3],[4],[5]]
y = [30000, 35000, 40000, 45000, 50000]

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Train model
model = LinearRegression()
model.fit(X_train, y_train)

# Predict
pred = model.predict(X_test)
print("MSE:", mean_squared_error(y_test, pred))
