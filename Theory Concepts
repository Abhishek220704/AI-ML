Part 1 – Python 


Core Python syntax & concepts

Data Structures

OOP

Advanced Python (decorators, generators, context managers)

Libraries for AI/ML

1️⃣ Core Python Concepts

Variables & Data Types → int, float, str, bool

Control Structures → if/else, loops, comprehensions

Functions → def, default arguments, *args, **kwargs

def greet(name="World"):
    return f"Hello, {name}!"

print(greet())       # Hello, World!
print(greet("AI"))   # Hello, AI!

2️⃣ Data Structures

Lists
nums = [1, 2, 3]
nums.append(4)      # [1,2,3,4]
nums.pop()          # removes 4

Tuples (immutable)
coords = (10, 20)

Sets (unique elements)
s = {1, 2, 2, 3}
print(s)  # {1, 2, 3}

Dictionaries
student = {"name": "Abhishek", "age": 22}
print(student["name"])  # Abhishek

3️⃣ OOP in Python

Classes & Objects

class Dog:
    def __init__(self, name):
        self.name = name
    
    def bark(self):
        return f"{self.name} says woof!"

d = Dog("Tommy")
print(d.bark())  # Tommy says woof!


Inheritance

class Animal:
    def speak(self):
        return "I make sounds"

class Cat(Animal):
    def speak(self):
        return "Meow!"

c = Cat()
print(c.speak())  # Meow!

4️⃣ Advanced Python

Decorators

def logger(func):
    def wrapper():
        print("Function is called")
        return func()
    return wrapper

@logger
def hello():
    print("Hello!")

hello()


Generators

def counter(n):
    for i in range(n):
        yield i

for x in counter(3):
    print(x)  # 0,1,2


Context Managers (with)

with open("data.txt", "w") as f:
    f.write("Hello AI")

5️⃣ Essential Libraries

NumPy → arrays, matrix operations

Pandas → DataFrames, filtering, groupby

Matplotlib/Seaborn → plotting

Scikit-learn → ML models

TensorFlow/PyTorch → Deep learning

📌 Example with Pandas:

import pandas as pd
data = {"Name": ["A", "B"], "Score": [85, 90]}
df = pd.DataFrame(data)
print(df[df["Score"] > 85])  # prints row with B

PART-2

🤖 1️⃣ What is Machine Learning?

ML = Making machines learn patterns from data without being explicitly programmed.

Types of ML:

Supervised Learning → Learn from labeled data.

Regression (predict numbers: house price, stock price).

Classification (predict categories: spam/not spam).

Unsupervised Learning → No labels, just structure.

Clustering (grouping: customer segmentation).

Dimensionality Reduction (PCA, t-SNE).

Reinforcement Learning → Agent learns by trial & error (self-driving car, game AI).

📈 2️⃣ Key Algorithms
(a) Regression

Linear Regression – predicts continuous values.

Equation:

y = w1x1 + w2x2 + ..... + b

📌 Example: Predict salary from years of experience.

(b) Classification

Logistic Regression – predicts probabilities (yes/no).

Uses sigmoid function to squash output between 0–1.

📌 Example: Spam vs. Not Spam.

(c) Decision Trees & Random Forest

Tree splits data based on features.

Random Forest = multiple trees + majority vote (reduces overfitting).


(d) Clustering

K-Means Clustering – groups data into K clusters.
Steps:

Choose K cluster centers.

Assign points to nearest center.

Recompute centers.

Repeat.

📌 Example: Grouping customers by spending habits.

3️⃣ Training & Evaluation
Common Metrics:

Regression → MSE, RMSE, MAE, R².

Classification → Accuracy, Precision, Recall, F1-score, ROC-AUC.

👉 Important Example:
Dataset = 95% negative class, 5% positive.
If model predicts all “negative” → Accuracy = 95%, but useless!
👉 Use Precision, Recall, F1.

Overfitting vs Underfitting

Overfitting → Model learns noise (great on train, bad on test).

Underfitting → Model too simple (bad on both).

✅ Solutions:

Overfitting → Regularization (L1/L2), Dropout, Pruning trees.

Underfitting → Add features, complex model.

4️⃣ Mini Example (Python)
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# Fake data: Years of experience vs Salary
X = [[1],[2],[3],[4],[5]]
y = [30000, 35000, 40000, 45000, 50000]

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Train model
model = LinearRegression()
model.fit(X_train, y_train)

# Predict
pred = model.predict(X_test)
print("MSE:", mean_squared_error(y_test, pred))
