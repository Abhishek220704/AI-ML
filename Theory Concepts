Part 1 â€“ Python 


Core Python syntax & concepts

Data Structures

OOP

Advanced Python (decorators, generators, context managers)

Libraries for AI/ML

1ï¸âƒ£ Core Python Concepts

Variables & Data Types â†’ int, float, str, bool

Control Structures â†’ if/else, loops, comprehensions

Functions â†’ def, default arguments, *args, **kwargs

def greet(name="World"):
    return f"Hello, {name}!"

print(greet())       # Hello, World!
print(greet("AI"))   # Hello, AI!

2ï¸âƒ£ Data Structures

Lists
nums = [1, 2, 3]
nums.append(4)      # [1,2,3,4]
nums.pop()          # removes 4

Tuples (immutable)
coords = (10, 20)

Sets (unique elements)
s = {1, 2, 2, 3}
print(s)  # {1, 2, 3}

Dictionaries
student = {"name": "Abhishek", "age": 22}
print(student["name"])  # Abhishek

3ï¸âƒ£ OOP in Python

Classes & Objects

class Dog:
    def __init__(self, name):
        self.name = name
    
    def bark(self):
        return f"{self.name} says woof!"

d = Dog("Tommy")
print(d.bark())  # Tommy says woof!


Inheritance

class Animal:
    def speak(self):
        return "I make sounds"

class Cat(Animal):
    def speak(self):
        return "Meow!"

c = Cat()
print(c.speak())  # Meow!

4ï¸âƒ£ Advanced Python

Decorators

def logger(func):
    def wrapper():
        print("Function is called")
        return func()
    return wrapper

@logger
def hello():
    print("Hello!")

hello()


Generators

def counter(n):
    for i in range(n):
        yield i

for x in counter(3):
    print(x)  # 0,1,2


Context Managers (with)

with open("data.txt", "w") as f:
    f.write("Hello AI")

5ï¸âƒ£ Essential Libraries

NumPy â†’ arrays, matrix operations

Pandas â†’ DataFrames, filtering, groupby

Matplotlib/Seaborn â†’ plotting

Scikit-learn â†’ ML models

TensorFlow/PyTorch â†’ Deep learning

ğŸ“Œ Example with Pandas:

import pandas as pd
data = {"Name": ["A", "B"], "Score": [85, 90]}
df = pd.DataFrame(data)
print(df[df["Score"] > 85])  # prints row with B

PART-2

ğŸ¤– 1ï¸âƒ£ What is Machine Learning?

ML = Making machines learn patterns from data without being explicitly programmed.

Types of ML:

Supervised Learning â†’ Learn from labeled data.

Regression (predict numbers: house price, stock price).

Classification (predict categories: spam/not spam).

Unsupervised Learning â†’ No labels, just structure.

Clustering (grouping: customer segmentation).

Dimensionality Reduction (PCA, t-SNE).

Reinforcement Learning â†’ Agent learns by trial & error (self-driving car, game AI).

ğŸ“ˆ 2ï¸âƒ£ Key Algorithms
(a) Regression

Linear Regression â€“ predicts continuous values.

Equation:

y = w1x1 + w2x2 + ..... + b

ğŸ“Œ Example: Predict salary from years of experience.

(b) Classification

Logistic Regression â€“ predicts probabilities (yes/no).

Uses sigmoid function to squash output between 0â€“1.

ğŸ“Œ Example: Spam vs. Not Spam.

(c) Decision Trees & Random Forest

Tree splits data based on features.

Random Forest = multiple trees + majority vote (reduces overfitting).


(d) Clustering

K-Means Clustering â€“ groups data into K clusters.
Steps:

Choose K cluster centers.

Assign points to nearest center.

Recompute centers.

Repeat.

ğŸ“Œ Example: Grouping customers by spending habits.

3ï¸âƒ£ Training & Evaluation
Common Metrics:

Regression â†’ MSE, RMSE, MAE, RÂ².

Classification â†’ Accuracy, Precision, Recall, F1-score, ROC-AUC.

ğŸ‘‰ Important Example:
Dataset = 95% negative class, 5% positive.
If model predicts all â€œnegativeâ€ â†’ Accuracy = 95%, but useless!
ğŸ‘‰ Use Precision, Recall, F1.

Overfitting vs Underfitting

Overfitting â†’ Model learns noise (great on train, bad on test).

Underfitting â†’ Model too simple (bad on both).

âœ… Solutions:

Overfitting â†’ Regularization (L1/L2), Dropout, Pruning trees.

Underfitting â†’ Add features, complex model.

4ï¸âƒ£ Mini Example (Python)
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# Fake data: Years of experience vs Salary
X = [[1],[2],[3],[4],[5]]
y = [30000, 35000, 40000, 45000, 50000]

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Train model
model = LinearRegression()
model.fit(X_train, y_train)

# Predict
pred = model.predict(X_test)
print("MSE:", mean_squared_error(y_test, pred))
